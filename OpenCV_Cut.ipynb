{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://brew.sh/index_ja.html\n",
    "\n",
    "http://qiita.com/Tama_maru/items/26a0509d2e30caa4a975\n",
    "\n",
    "http://qiita.com/daisukeokaoss/items/738566e9f24d114651ab\n",
    "\n",
    "http://qiita.com/wwacky/items/98d8be2844fa1b778323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OpenCVをbrewを使ってインストールする。以下はターミナルで実行。\n",
    "#brew tap homebrew/science\n",
    "#brew install opencv　及び　brew install opencv3 --with-python3　#opencv3はpython3対応で、\"import cv2\"でインポートできる.\n",
    "#パスを通す\n",
    "#$ echo /usr/local/Cellar/opencv3/3.2.0/lib/python3.6/site-packages >> /usr/local/lib/python3.6/site-packages/opencv3.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2343ed2cf407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#HAAR分類器の顔検出用の特徴量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "#Pythonで動かす\n",
    "#recognize.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import cv2\n",
    "\n",
    "#HAAR分類器の顔検出用の特徴量\n",
    "#cascade_path = \"/usr/local/opt/opencv/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "cascade_path = \"/usr/local/opt/opencv/share/OpenCV/haarcascades/haarcascade_frontalface_alt.xml\"\n",
    "#cascade_path = \"/usr/local/opt/opencv/share/OpenCV/haarcascades/haarcascade_frontalface_alt2.xml\"\n",
    "#cascade_path = \"/usr/local/opt/opencv/share/OpenCV/haarcascades/haarcascade_frontalface_alt_tree.xml\"\n",
    "\n",
    "\n",
    "image_path = \"lena.jpg\"\n",
    "\n",
    "color = (255, 255, 255) #白\n",
    "#color = (0, 0, 0) #黒\n",
    "\n",
    "#ファイル読み込み\n",
    "image = cv2.imread(image_path)\n",
    "#グレースケール変換\n",
    "image_gray = cv2.cvtColor(image, cv2.cv.CV_BGR2GRAY)\n",
    "\n",
    "#カスケード分類器の特徴量を取得する\n",
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "#物体認識（顔認識）の実行\n",
    "#image – CV_8U 型の行列．ここに格納されている画像中から物体が検出されます\n",
    "#objects – 矩形を要素とするベクトル．それぞれの矩形は，検出した物体を含みます\n",
    "#scaleFactor – 各画像スケールにおける縮小量を表します\n",
    "#minNeighbors – 物体候補となる矩形は，最低でもこの数だけの近傍矩形を含む必要があります\n",
    "#flags – このパラメータは，新しいカスケードでは利用されません．古いカスケードに対しては，cvHaarDetectObjects 関数の場合と同じ意味を持ちます\n",
    "#minSize – 物体が取り得る最小サイズ．これよりも小さい物体は無視されます\n",
    "facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=1, minSize=(1, 1))\n",
    "#facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=3, minSize=(10, 10), flags = cv2.cv.CV_HAAR_SCALE_IMAGE)\n",
    "\n",
    "print(\"face rectangle\")\n",
    "print(facerect)\n",
    "\n",
    "if len(facerect) > 0:\n",
    "    #検出した顔を囲む矩形の作成\n",
    "    for rect in facerect:\n",
    "        cv2.rectangle(image, tuple(rect[0:2]),tuple(rect[0:2]+rect[2:4]), color, thickness=2)\n",
    "\n",
    "    #認識結果の保存\n",
    "    cv2.imwrite(\"detected.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://qiita.com/lrf141/items/ff1462c5c6b7b3207775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#顔探索用のカスケード型分類器を取得\n",
    "face_cascade = cv2.CascadeClassifier(haarcascade_frontalface_default.xmlのパスを渡す)\n",
    "\n",
    "img = cv2.imread(\"Lenna.png\")\n",
    "result = cv2.imread(\"Lenna.png\")\n",
    "\n",
    "#読み込んだ画像をグレースケールに変換\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#分類器で顔を認識する\n",
    "face = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "if 0 < len(face):\n",
    "\n",
    "    print \"get face\"\n",
    "\n",
    "    for (x,y,w,h) in face:\n",
    "\n",
    "        #顔の部分だけ切り抜いてモザイク処理をする\n",
    "        cut_img = img[y:y+h,x:x+w]\n",
    "        cut_face = cut_img.shape[:2][::-1]\n",
    "        #10分の1にする\n",
    "        cut_img = cv2.resize(cut_img,(cut_face[0]/10, cut_face[0]/10))\n",
    "        #画像を元のサイズに拡大\n",
    "        cut_img = cv2.resize(cut_img,cut_face,interpolation = cv2.cv.CV_INTER_NN)\n",
    "\n",
    "        #モザイク処理した部分を重ねる\n",
    "        result[y:y+h,x:x+w] = cut_img\n",
    "\n",
    "else:\n",
    "\n",
    "    print \"no face\"\n",
    "\n",
    "\n",
    "cv2.imshow(\"face mosaic\",result)\n",
    "#cv2.imwrite(\"output file name\",result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
